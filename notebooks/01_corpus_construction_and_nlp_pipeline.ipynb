{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d3a212",
   "metadata": {},
   "source": [
    "## Import des biblioth√®ques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b263d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from Corpus import Corpus\n",
    "import praw\n",
    "from datetime import datetime\n",
    "import urllib.request\n",
    "import xmltodict\n",
    "import ssl\n",
    "import certifi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5926caa",
   "metadata": {},
   "source": [
    "## Extraction de donn√©es depuis Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extraire_reddit(corpus, theme, mot_cles=None):\n",
    "    if mot_cles is None:\n",
    "        mot_cles = [\n",
    "            'climate', 'climatechange', 'environment', 'sustainability',\n",
    "            'carbonfootprint', 'ecology', 'greenenergy', 'climateaction'\n",
    "        ]\n",
    "    \n",
    "    print(\"\\n--- Extraction Reddit ---\")\n",
    "    \n",
    "    # Configuration Reddit API\n",
    "    reddit = praw.Reddit(\n",
    "        client_id='_qZmFflED2oGl3LmqZvqBg',\n",
    "        client_secret='1wQi5AamyCOBlq5HQqbpu85PDRjySQ',\n",
    "        user_agent='projet_api'\n",
    "    )\n",
    "    \n",
    "    for mot in mot_cles:\n",
    "        try:\n",
    "            posts = reddit.subreddit(mot).top(limit=20)\n",
    "            for post in posts:\n",
    "                text = post.selftext.replace(\"\\n\", \" \").strip()\n",
    "                if text == \"\":\n",
    "                    continue\n",
    "\n",
    "                corpus.add_document(\n",
    "                    titre=post.title,\n",
    "                    auteur=str(post.author) if post.author else \"Unknown\",\n",
    "                    date=datetime.fromtimestamp(post.created_utc).strftime(\"%Y-%m-%d\"),\n",
    "                    url=f\"https://reddit.com{post.permalink}\",\n",
    "                    texte=text\n",
    "                )\n",
    "                print(f\"  ‚úì Reddit: {post.title[:50]}...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Erreur avec le subreddit '{mot}': {e}\")\n",
    "    \n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e84a0",
   "metadata": {},
   "source": [
    "## Extraction de donn√©es scientifiques depuis ArXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00a0764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extraire_arxiv(corpus, theme, max_results=10):\n",
    "    \"\"\"\n",
    "    Extrait les articles ArXiv et les ajoute au corpus.\n",
    "    \n",
    "    Args:\n",
    "        corpus: Instance de Corpus\n",
    "        theme: Th√®me de recherche\n",
    "        max_results: Nombre max d'articles √† r√©cup√©rer\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Extraction ArXiv ---\")\n",
    "    \n",
    "    # Configuration SSL pour ArXiv\n",
    "    ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "    url = f\"https://export.arxiv.org/api/query?search_query=all:{theme}&start=0&max_results={max_results}\"\n",
    "    \n",
    "    try:\n",
    "        # R√©cup√©ration des donn√©es\n",
    "        response = urllib.request.urlopen(url, context=ssl_context)\n",
    "        data = xmltodict.parse(response.read())\n",
    "        \n",
    "        entries = data[\"feed\"][\"entry\"]\n",
    "        if isinstance(entries, dict):\n",
    "            entries = [entries]\n",
    "        \n",
    "        for entry in entries:\n",
    "            # Gestion des auteurs\n",
    "            auteurs = entry[\"author\"]\n",
    "            if isinstance(auteurs, dict):\n",
    "                auteurs = [auteurs]\n",
    "            auteur_str = \", \".join(a[\"name\"] for a in auteurs)\n",
    "            \n",
    "            corpus.add_document(\n",
    "                titre=entry[\"title\"].strip(),\n",
    "                auteur=auteur_str,\n",
    "                date=entry[\"published\"],\n",
    "                url=entry[\"id\"],\n",
    "                texte=entry[\"summary\"].strip()\n",
    "            )\n",
    "            print(f\"  ‚úì ArXiv: {entry['title'][:50]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Erreur avec ArXiv: {e}\")\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101377c6",
   "metadata": {},
   "source": [
    "## Construction ou chargement du corpus principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7f3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chargement du corpus depuis climatechange_corpus_new.csv...\n",
      "Corpus charg√© depuis climatechange_corpus_new.csv (28 documents)\n",
      "Corpus charg√© : 28 documents, 28 auteurs\n"
     ]
    }
   ],
   "source": [
    "theme = \"climatechange\"\n",
    "filename = f\"{theme}_corpus_new.csv\"\n",
    "\n",
    "corpus = Corpus(f\"Corpus_{theme}\")\n",
    "\n",
    "# --- Si le fichier existe : charger ---\n",
    "if os.path.exists(filename):\n",
    "    print(f\"\\nChargement du corpus depuis {filename}...\")\n",
    "    corpus.load(filename)\n",
    "    print(f\"Corpus charg√© : {corpus.ndoc} documents, {corpus.naut} auteurs\")\n",
    "\n",
    "# --- Sinon : construire le corpus ---\n",
    "else:\n",
    "    print(f\"\\nAucun fichier trouv√©. Construction du corpus '{theme}'...\")\n",
    "    \n",
    "    # Appel des fonctions d'extraction\n",
    "    corpus = extraire_reddit(corpus, theme)\n",
    "    corpus = extraire_arxiv(corpus, theme, max_results=15)\n",
    "    \n",
    "    # Sauvegarde du corpus\n",
    "    corpus.save(filename)\n",
    "    print(f\"\\n‚úÖ Corpus construit et sauvegard√© : {corpus.ndoc} documents, {corpus.naut} auteurs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f828026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(filename):\n",
    "    print(\"\\nSauvegarde du corpus...\")\n",
    "    corpus.save(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c7e22b",
   "metadata": {},
   "source": [
    "# V√©rification du corpus avec des documents sp√©cialis√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b80dc9",
   "metadata": {},
   "source": [
    "## üß™Test avec un document Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b754ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_0 : Reddit - Mon post Reddit\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from Corpus import Corpus\n",
    "from RedditDocument import RedditDocument\n",
    "from ArxivDocument import ArxivDocument\n",
    "\n",
    "corpus = Corpus(\"Test\")\n",
    "\n",
    "# Ajout manuel d'un document Reddit\n",
    "r = RedditDocument(\n",
    "    titre=\"Mon post Reddit\",\n",
    "    auteur=\"Alice\",\n",
    "    date=\"2024-11-10\",\n",
    "    url=\"https://reddit.com/r/python\",\n",
    "    texte=\"Un post int√©ressant\",\n",
    "    nb_comments=120\n",
    ")\n",
    "\n",
    "corpus.id2doc[\"doc_0\"] = r\n",
    "corpus.ndoc += 1\n",
    "\n",
    "corpus.afficher_sources()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdac28c",
   "metadata": {},
   "source": [
    "## üß™ Test avec un document ArXiv personnalis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7026e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_0 : Reddit - Mon post Reddit\n",
      "doc_1 : Arxiv - Article d'IA\n"
     ]
    }
   ],
   "source": [
    "a = ArxivDocument(\n",
    "    titre=\"Article d'IA\",\n",
    "    auteur=\"Yann LeCun\",\n",
    "    date=\"2023-09-02\",\n",
    "    url=\"https://arxiv.org/abs/1234.5678\",\n",
    "    texte=\"R√©sum√©...\",\n",
    "    co_auteurs=[\"Hinton\", \"Bengio\"]\n",
    ")\n",
    "\n",
    "corpus.id2doc[\"doc_1\"] = a\n",
    "corpus.ndoc += 1\n",
    "corpus.afficher_sources()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514723b0",
   "metadata": {},
   "source": [
    "# Tests fonctionnels ‚Äì TD6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b69581c",
   "metadata": {},
   "source": [
    "## üìù Cr√©ation d‚Äôun corpus de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5918394",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(\"Test TD6\")\n",
    "\n",
    "corpus.add_document(\n",
    "    \"Climat et pollution\",\n",
    "    \"Alice\",\n",
    "    \"2024-01-10\",\n",
    "    \"http://test1.com\",\n",
    "    \"Le changement climatique est rapide. Pollution et climat.\"\n",
    ")\n",
    "\n",
    "corpus.add_document(\n",
    "    \"Energie renouvelable\",\n",
    "    \"Bob\",\n",
    "    \"2024-01-11\",\n",
    "    \"http://test2.com\",\n",
    "    \"L'√©nergie renouvelable lutte contre le changement climatique.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c32df5",
   "metadata": {},
   "source": [
    "## üîç Recherche textuelle et concordancier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67f8da4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doc_0', <document.Document at 0x1acf48bcd10>),\n",
       " ('doc_1', <document.Document at 0x1acf48bc310>)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.search(\"climatique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaa45adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Le changement', 'climatique', 'est rapide. Pollution et clim', 'doc_0')\n",
      "('le lutte contre le changement', 'climatique', '.', 'doc_1')\n"
     ]
    }
   ],
   "source": [
    "for c in corpus.concorde(\"climatique\"):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb0a487",
   "metadata": {},
   "source": [
    "## üßπ Nettoyage et normalisation des textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1f8068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: Le changement climatique est rapide. Pollution et climat.\n",
      "AFTER: le changement climatique est rapide pollution et climat\n"
     ]
    }
   ],
   "source": [
    "print(\"BEFORE:\", corpus.id2doc[\"doc_0\"].texte)\n",
    "corpus.nettoyer_texte()\n",
    "print(\"AFTER:\", corpus.id2doc[\"doc_0\"].texte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0d4bd",
   "metadata": {},
   "source": [
    "## üìö Construction du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21bd3e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['changement',\n",
       " 'climat',\n",
       " 'climatique',\n",
       " 'contre',\n",
       " 'est',\n",
       " 'et',\n",
       " 'l',\n",
       " 'le',\n",
       " 'lutte',\n",
       " 'pollution',\n",
       " 'rapide',\n",
       " 'renouvelable',\n",
       " '√©nergie']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.build_vocab()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8b577",
   "metadata": {},
   "source": [
    "## üìä Analyse statistique du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1bbfb",
   "metadata": {},
   "source": [
    "### Fr√©quence des termes (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc99af2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>changement</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climatique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rapide</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollution</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climat</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>√©nergie</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renouvelable</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lutte</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contre</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              term_frequency\n",
       "le                         2\n",
       "changement                 2\n",
       "climatique                 2\n",
       "est                        1\n",
       "rapide                     1\n",
       "pollution                  1\n",
       "et                         1\n",
       "climat                     1\n",
       "l                          1\n",
       "√©nergie                    1\n",
       "renouvelable               1\n",
       "lutte                      1\n",
       "contre                     1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.term_frequency()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a650b0",
   "metadata": {},
   "source": [
    "### Fr√©quence documentaire (DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97c80a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>changement</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climat</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climatique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contre</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lutte</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollution</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rapide</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renouvelable</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>√©nergie</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              document_frequency\n",
       "changement                     2\n",
       "climat                         1\n",
       "climatique                     2\n",
       "contre                         1\n",
       "est                            1\n",
       "et                             1\n",
       "l                              1\n",
       "le                             2\n",
       "lutte                          1\n",
       "pollution                      1\n",
       "rapide                         1\n",
       "renouvelable                   1\n",
       "√©nergie                        1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.document_frequency()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ae044",
   "metadata": {},
   "source": [
    "# TD7 ‚Äì Vectorisation et moteur de recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6e4b6",
   "metadata": {},
   "source": [
    "## Construction de la matrice Documents √ó Mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulaire: ['_update', 'a', 'able', 'about', 'absolute', 'absolutely', 'ac', 'accelerating', 'accepted', 'according', 'accurate', 'across', 'act', 'action', 'activists', 'actual', 'actually', 'added', 'adding', 'addition', 'additional', 'address', 'adjust', 'adk', 'advances', 'advantage', 'aenocyon', 'affected', 'affecting', 'after', 'aftermath', 'ago', 'agriculture', 'air', 'al', 'albedo', 'albeit', 'all', 'allegany', 'allowed', 'almond', 'almost', 'along', 'already', 'also', 'always', 'am', 'amount', 'an', 'analog', 'analysis', 'ancient', 'and', 'animal', 'animals', 'annual', 'another', 'answer', 'any', 'anymore', 'anyone', 'anything', 'appealing', 'apply', 'appreciate', 'approaches', 'are', 'area', 'areas', 'argument', 'arizona', 'around', 'arrays', 'article', 'articles', 'as', 'ashwani', 'asia', 'ask', 'assessment', 'assume', 'assumption', 'at', 'atmosphere', 'attention', 'attract', 'attracting', 'authorities', 'auto', 'automatically', 'avoiding', 'awareness', 'b', 'ba', 'back', 'bad', 'bag', 'balance', 'banking', 'barcelona', 'barely', 'based', 'basic', 'be', 'beaches', 'because', 'become', 'beeding', 'been', 'bees', 'beginning', 'behavior', 'being', 'beings', 'below', 'bernie', 'best', 'better', 'between', 'big', 'bigger', 'bill', 'billions', 'bills', 'biodiversity', 'biological', 'biologist', 'biology', 'biomethane', 'birds', 'bit', 'black', 'blocked', 'blow', 'bone', 'book', 'boom', 'bothers', 'bowl', 'breach', 'break', 'breeding', 'bridges', 'broke', 'build', 'building', 'builds', 'bushes', 'but', 'by', 'c', 'caffeine', 'california', 'call', 'called', 'campaigning', 'can', 'canal', 'canals', 'canary', 'canids', 'capital', 'caps', 'captured', 'capturing', 'carbon', 'care', 'causal', 'caused', 'causing', 'cc', 'cdcd', 'centres', 'century', 'certification', 'cetaceans', 'ch', 'chance', 'change', 'chapter', 'characteristics', 'check', 'choir', 'classified', 'clean', 'cleaning', 'cleanup', 'climate', 'climatechange', 'climateinteractive', 'close', 'clothing', 'club', 'co', 'coastal', 'coastline', 'coexist', 'coffee', 'cold', 'collaborate', 'collapsing', 'colleagues', 'college', 'collided', 'com', 'combat', 'combination', 'combined', 'come', 'comfort', 'comfortable', 'coming', 'comments', 'common', 'communication', 'communities', 'community', 'company', 'compare', 'compared', 'compelling', 'competitiveness', 'complete', 'completely', 'computer', 'concern', 'concerned', 'concerning', 'concerns', 'conduct', 'conducted', 'conducting', 'congress', 'congressional', 'connect', 'connected', 'connecting', 'connections', 'consider', 'considerations', 'considered', 'conspiracy', 'construction', 'contamination', 'continue', 'contractor', 'contribute', 'contributing', 'contribution', 'control', 'controls', 'convince', 'cool', 'cooler', 'cooling', 'cost', 'cotton', 'could', 'counterproductive', 'counties', 'countries', 'country', 'county', 'course', 'cover', 'coverage', 'co‚ÇÇ', 'crazy', 'crisp', 'critical', 'crops', 'crossed', 'curious', 'current', 'curtailing', 'cut', 'cynic', 'd', 'daily', 'dallas', 'dangerous', 'data', 'day', 'daylight', 'days', 'de', 'deaths', 'december', 'dedication', 'deforestation', 'deforestation_update', 'dehumidifier', 'dent', 'depleted', 'descriptors', 'desert', 'deserves', 'despite', 'destroyed', 'destroying', 'details', 'developed', 'development', 'did', 'different', 'digital', 'direwolf', 'direwolves', 'disaster', 'disasters', 'diseases', 'dismissed', 'dispersal', 'distribute', 'district', 'disturbances', 'diversity', 'dna', 'dnr', 'do', 'docs', 'does', 'doesn', 'doi', 'doing', 'dollars', 'don', 'donate', 'donating', 'done', 'doors', 'dots', 'double', 'down', 'downpours', 'dr', 'driven', 'driver', 'driving', 'drosophila', 'droughts', 'drugged', 'dry', 'e', 'each', 'early', 'earnest', 'earth', 'earthobservatory', 'east', 'ecological', 'ecology', 'economic', 'economics', 'economy', 'ecosystem', 'ecosystems', 'editor', 'educate', 'effect', 'effectiveness', 'efficiently', 'efforts', 'either', 'elected', 'election', 'electrical', 'electricity', 'electrification', 'eliminate', 'else', 'elsewhere', 'emissions', 'emitted', 'en', 'encouraged', 'encouraging', 'ends', 'energy', 'enjoy', 'enjoying', 'entirely', 'environment', 'environmental', 'environmentalists', 'environmentalvoter', 'erqilih', 'espresso', 'established', 'estimate', 'et', 'eu', 'eua', 'european', 'even', 'events', 'eventually', 'ever', 'every', 'everyone', 'example', 'examples', 'exchange', 'existing', 'expedite', 'expensive', 'experience', 'experiences', 'experiencing', 'experts', 'explain', 'exposure', 'extended', 'extinct', 'extinction', 'extreme', 'extremely', 'extremist', 'fact', 'faipqlscdo', 'family', 'far', 'farmland', 'fascinating', 'fast', 'faster', 'father', 'features', 'feedback', 'feeding', 'feel', 'feeley', 'feels', 'few', 'fight', 'fighting', 'finally', 'find', 'findings', 'first', 'fish', 'fisting', 'flipped', 'flooding', 'florida', 'focus', 'folks', 'following', 'food', 'footprints', 'for', 'forest', 'forested', 'forests', 'formal', 'format', 'forms', 'forward', 'found', 'fox', 'foxes', 'framed', 'francisco', 'frederick', 'free', 'fresh', 'freshwater', 'fringe', 'from', 'frustrating', 'fuel', 'full', 'fun', 'function', 'funding', 'funds', 'funtion', 'fur', 'furbearer', 'future', 'g', 'gallberry', 'game', 'garage', 'garrett', 'gators', 'gendercritical', 'gene', 'general', 'generate', 'generation', 'generations', 'generators', 'genetic', 'genus', 'geologic', 'geology', 'get', 'getting', 'gila', 'glaciologist', 'glass', 'global', 'goes', 'going', 'good', 'google', 'got', 'gov', 'government', 'grass', 'grassroots', 'gray', 'great', 'green', 'grey', 'grid', 'grocery', 'ground', 'grow', 'growth', 'guys', 'had', 'hangs', 'happened', 'happening', 'happens', 'harm', 'has', 'have', 'haven', 'hayek', 'he', 'health', 'hear', 'heard', 'hearing', 'heat', 'heating', 'hello', 'help', 'helping', 'here', 'hey', 'hi', 'high', 'higher', 'him', 'himalayan', 'himalayas', 'his', 'history', 'home', 'homes', 'honey', 'hope', 'horrified', 'hotel', 'hour', 'hours', 'house', 'how', 'howe', 'htk', 'http', 'https', 'huge', 'human', 'humans', 'humid', 'humidity', 'hunting', 'huntingregs_card', 'husband', 'hvac', 'hw', 'hypothesize', 'i', 'iagb', 'ice', 'idea', 'ideologies', 'idk', 'idnr', 'if', 'ikuza', 'images', 'imo', 'impact', 'imperative', 'importance', 'important', 'improve', 'in', 'incapable', 'incel', 'inches', 'include', 'including', 'increase', 'increasing', 'incumbent', 'independent', 'india', 'indian', 'indicate', 'indicative', 'inevitably', 'inference', 'inflation', 'influence', 'influenced', 'info', 'infographics', 'information', 'informed', 'informing', 'infrastructure', 'initiative', 'input', 'insane', 'inside', 'insights', 'instagram', 'installation', 'instance', 'instead', 'institute', 'insulation', 'interaction', 'interactions', 'interactive', 'international', 'interview', 'into', 'investigation', 'involuntarily', 'involved', 'iowa', 'iowadnr', 'ipcc', 'irrigation', 'is', 'isn', 'issues', 'it', 'its', 'itself', 'j', 'jain', 'jainforcongress', 'jargon', 'joe', 'join', 'josephpoore', 'jpg', 'judd', 'just', 'k', 'keep', 'keeps', 'key', 'kidding', 'kill', 'kilometres', 'kind', 'know', 'knowledge', 'known', 'knows', 'l', 'lack', 'ladakh', 'land', 'landmass', 'landscape', 'language', 'large', 'larger', 'largest', 'lead', 'leading', 'leagueoflegends', 'leaning', 'learn', 'learned', 'led', 'left', 'leisuuby', 'less', 'lessons', 'let', 'lethal', 'letter', 'letters', 'level', 'lighting', 'like', 'likely', 'limit', 'limited', 'line', 'little', 'live', 'living', 'local', 'localized', 'locked', 'look', 'looking', 'looks', 'loop', 'lose', 'loss', 'losses', 'lot', 'louisiana', 'love', 'low', 'm', 'machovina', 'made', 'main', 'mainstream', 'maintenance', 'major', 'majority', 'make', 'makes', 'making', 'manageable', 'manuscript', 'many', 'maryland', 'mass', 'massive', 'mastering', 'match', 'matched', 'matter', 'matters', 'matthew', 'may', 'maybe', 'me', 'meaningful', 'measures', 'mechanism', 'mechanisms', 'media', 'medicare', 'meds', 'members', 'mentioned', 'merced', 'meters', 'methods', 'mid', 'might', 'milder', 'millennia', 'millennial', 'million', 'millions', 'mind', 'minimum', 'mirrors', 'miserable', 'misreading', 'miss', 'mistaken', 'mit', 'mm', 'model', 'modern', 'moisture', 'money', 'monsoon', 'montgomery', 'more', 'morning', 'most', 'motivate', 'motivated', 'mow', 'much', 'mulching', 'mw', 'my', 'n', 'name', 'nasa', 'national', 'nations', 'native', 'natural', 'nature', 'nba', 'nc', 'ncbi', 'near', 'neat', 'necessary', 'nectar', 'need', 'needed', 'needs', 'negligible', 'nemecek', 'nett', 'neuse', 'new', 'newcomers', 'news', 'newspaper', 'next', 'nexus', 'nih', 'nimble', 'nlm', 'no', 'non', 'nonexistent', 'normal', 'north', 'northeast', 'northern', 'not', 'nothing', 'noticed', 'nov', 'now', 'number', 'occupancy', 'oedpwf', 'of', 'off', 'offer', 'offers', 'office', 'often', 'oil', 'ok', 'older', 'on', 'one', 'ones', 'ongoing', 'online', 'only', 'open', 'operations', 'opportunity', 'optimize', 'or', 'order', 'org', 'organizations', 'other', 'our', 'out', 'outside', 'over', 'overall', 'own', 'pair', 'palm', 'palmettos', 'pandemics', 'panels', 'paper', 'part', 'participate', 'parts', 'passionate', 'past', 'pdf', 'people', 'percentage', 'perform', 'person', 'petroleum', 'phd', 'phone', 'php', 'pieces', 'pilot', 'pitch', 'pivot', 'pjpg', 'places', 'planet', 'plans', 'plants', 'platforms', 'play', 'played', 'please', 'plumbing', 'pmc', 'point', 'points', 'policies', 'policy', 'politics', 'pollination', 'pollution', 'pool', 'poore', 'population', 'portable', 'portals', 'possible', 'post', 'potential', 'potentially', 'power', 'powering', 'powers', 'pp', 'pq', 'practical', 'pre', 'preaching', 'predators', 'predominate', 'preface', 'preserve', 'preserving', 'press', 'pressure', 'pretty', 'preview', 'prices', 'primarily', 'primary', 'priorities', 'probably', 'produce', 'products', 'professional', 'proficient', 'program', 'project', 'projected', 'projects', 'prominent', 'promising', 'promoting', 'property', 'provide', 'public', 'pubmed', 'pushed', 'put', 'putting', 'pv', 'question', 'questions', 'quite', 'quoted', 'r', 'radiation', 'rain', 'rainforests', 'rains', 'raising', 'rambly', 'rarely', 'rather', 're', 'reach', 'read', 'real', 'really', 'rebred', 'receive', 'recent', 'recently', 'recognition', 'recommend', 'record', 'recorded', 'recovery', 'recruited', 'redd', 'reddit', 'reduce', 'reducing', 'reduction', 'reductions', 'reels', 'reflect', 'reflectiveness', 'reflectivity', 'regarding', 'region', 'regions', 'regular', 'regularly', 'relatively', 'remains', 'removed', 'removing', 'renewables', 'renovations', 'repeating', 'replacing', 'represents', 'require', 'research', 'researcher', 'researching', 'resemble', 'reshapes', 'resort', 'responsive', 'rest', 'resulted', 'results', 'reveal', 'rewiring', 'rewriting', 'richard', 'ridiculously', 'right', 'ripple', 'rise', 'risk', 'river', 'rivers', 'rng', 'roads', 'rock', 'rockthevote', 'rogan', 'role', 'roof', 'roofs', 'rrtdr', 'run', 'running', 'russia', 'russian', 's', 'sahara', 'said', 'sake', 'salmon', 'same', 'samples', 'san', 'sanders', 'sapped', 'satellite', 'saturated', 'saving', 'saw', 'say', 'says', 'scale', 'scary', 'science', 'scienctists', 'scope', 'sea', 'season', 'seat', 'second', 'security', 'see', 'seeing', 'seem', 'seems', 'seen', 'selective', 'sense', 'september', 'sequestering', 'series', 'serve', 'services', 'sessions', 'setup', 'severely', 'shape', 'share', 'should', 'shoving', 'sierra', 'sierraclubindependentaction', 'significant', 'silence', 'similar', 'simplification', 'simplified', 'simulator', 'simultaneously', 'since', 'sincerely', 'sinks', 'slammed', 'sleeping', 'slight', 'sloan', 'slopes', 'small', 'smart', 'smelting', 'snow', 'so', 'social', 'solar', 'solely', 'solutions', 'some', 'something', 'sorry', 'source', 'sources', 'sourcing', 'south', 'southwest', 'space', 'spaces', 'specialists', 'species', 'specific', 'specifically', 'speculate', 'speed', 'spill', 'spillage', 'spotted', 'spread', 'srccl', 'st', 'staring', 'started', 'state', 'states', 'staying', 'stays', 'stick', 'still', 'storage', 'store', 'stories', 'storing', 'story', 'straight', 'strategic', 'stream', 'strong', 'struggling', 'student', 'studies', 'studio', 'study', 'stuff', 'subreddit', 'subsequent', 'suffers', 'suggest', 'suggested', 'suggesting', 'suggestions', 'summer', 'sunlight', 'sunny', 'superficially', 'support', 'supposed', 'sure', 'surrounded', 'survey', 'sustainability', 'swings', 'switching', 'system', 'systems', 't', 'take', 'takeaction', 'takeaway', 'tales', 'tankers', 'teaches', 'teams', 'tec', 'techniques', 'tell', 'temperature', 'temperatures', 'temprature', 'temps', 'tens', 'terrified', 'texas', 'text', 'texting', 'th', 'than', 'thank', 'thanks', 'that', 'the', 'the_donald', 'their', 'them', 'theories', 'there', 'these', 'they', 'thing', 'think', 'thinking', 'this', 'tho', 'those', 'thought', 'thousand', 'three', 'thrive', 'thrived', 'through', 'tibet', 'time', 'times', 'tips', 'tl', 'to', 'today', 'tomato', 'tonnes', 'tons', 'too', 'tool', 'toolkit', 'top', 'total', 'toxic', 'toxic_tales_eco', 'tracking', 'tract', 'tragedy', 'traits', 'transition', 'trapper', 'trapping', 'tree', 'trees', 'tried', 'try', 'turbines', 'turn', 'turns', 'two', 'u', 'uc', 'ukraine', 'ukrainians', 'unable', 'underestimates', 'understand', 'understandable', 'uni', 'unprecedented', 'unsuitable', 'up', 'uploads', 'upon', 'ups', 'urgently', 'us', 'usc', 'use', 'used', 'useful', 'users', 'using', 'usual', 'utterly', 'vague', 'vaguely', 've', 'vegetation', 'venture', 'very', 'veterinary', 'viable', 'viewform', 'virtually', 'visual', 'visuals', 'volunteer', 'volunteers', 'vote', 'votefwd', 'voter', 'voters', 'vs', 'w', 'wadia', 'wage', 'wall', 'walls', 'wanted', 'wants', 'warming', 'was', 'washington', 'washingtonpost', 'water', 'waters', 'waves', 'way', 'ways', 'we', 'weather', 'web', 'webp', 'weeks', 'welcoming', 'well', 'went', 'western', 'wetlands', 'what', 'when', 'where', 'which', 'while', 'whlie', 'who', 'whole', 'why', 'wider', 'width', 'wihg', 'wiki', 'wikipedia', 'wildlife', 'will', 'wind', 'windows', 'winds', 'winter', 'with', 'without', 'wolf', 'wolves', 'won', 'wondering', 'word', 'work', 'worked', 'working', 'workshop', 'world', 'worried', 'worry', 'would', 'wouldn', 'wreck', 'writing', 'wvik', 'www', 'x', 'year', 'years', 'yellowstone', 'you', 'your', 'zanskar', 'zone', 'zones', 'zoonotic']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#transformer les documents en une matrice Documents √ó Mots\n",
    "vocab = corpus.build_vocab()\n",
    "print(\"\\nVocabulaire:\", vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9f095",
   "metadata": {},
   "source": [
    "## Moteur de recherche TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df629847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>titre</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>doc_27</td>\n",
       "      <td>Climate Interactive &amp; MIT Launch [Free] Traini...</td>\n",
       "      <td>0.196290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>doc_55</td>\n",
       "      <td>Climate Interactive &amp; MIT Launch [Free] Traini...</td>\n",
       "      <td>0.196290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>doc_31</td>\n",
       "      <td>Joe Rogan Fact-Checks Bernie Sanders on Climat...</td>\n",
       "      <td>0.179234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc_3</td>\n",
       "      <td>Joe Rogan Fact-Checks Bernie Sanders on Climat...</td>\n",
       "      <td>0.179234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_0</td>\n",
       "      <td>Holy sh*t - for the first time EVER, monsoon w...</td>\n",
       "      <td>0.086982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              titre     score\n",
       "27  doc_27  Climate Interactive & MIT Launch [Free] Traini...  0.196290\n",
       "55  doc_55  Climate Interactive & MIT Launch [Free] Traini...  0.196290\n",
       "31  doc_31  Joe Rogan Fact-Checks Bernie Sanders on Climat...  0.179234\n",
       "3    doc_3  Joe Rogan Fact-Checks Bernie Sanders on Climat...  0.179234\n",
       "0    doc_0  Holy sh*t - for the first time EVER, monsoon w...  0.086982"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SearchEngine import SearchEngine\n",
    "\n",
    "engine = SearchEngine(corpus, mode=\"tfidf\")\n",
    "engine.search(\"climate warming pollution water\", top=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
